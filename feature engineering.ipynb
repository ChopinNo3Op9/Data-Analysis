{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data with missing values\n",
    "data = {'y': [2, 4, 6, 8],\n",
    "        'feature1': [1, 2, np.nan, 4],\n",
    "        'feature2': [4, np.nan, 6, 7]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Impute missing values using the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "# imputer = SimpleImputer(strategy='median')\n",
    "# imputer = SimpleImputer(strategy='most_frequent')\n",
    "# imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Validate data types\n",
    "df_cleaned.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Remove duplicates\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample categorical data\n",
    "data = {'category': ['A', 'B', 'C', 'A']}\n",
    "df = pd.DataFrame(data)\n",
    "df = pd.concat([df_cleaned, df], axis=1)\n",
    "# df = pd.concat([df_cleaned, df]) # Concatenate df and df_cleaned vertically\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encode categorical data\n",
    "df = pd.get_dummies(df, columns=['category'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_columns = ['category_A', 'category_B', 'category_C']\n",
    "df[boolean_columns] = df[boolean_columns].astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features, normalize the range of independent variables or features of data\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df.iloc[:, :3]), columns=df.columns[:3])\n",
    "df = pd.concat([df_scaled, df.iloc[:, 3:]], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create polynomial features, creates polynomial features (degree 2) from the existing features, which can help in capturing relationships between features.\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "df_poly = pd.DataFrame(poly.fit_transform(df.iloc[:, :3]), columns=poly.get_feature_names_out())\n",
    "df_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_poly, df.iloc[:, 3:]], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually create polynomial features (degree 2)\n",
    "df['feature1_squared'] = df['feature1'] ** 2\n",
    "df['feature2_squared'] = df['feature2'] ** 2\n",
    "df['feature1_x_feature2'] = df['feature1'] * df['feature2']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the best 2 features based on the ANOVA F-value between feature and target.\n",
    "# The F-value is a statistic used to compare the variances between different groups, \n",
    "# and in the context of feature selection, it assesses whether the mean of the target variable differs significantly across the different values of the feature.\n",
    "# Determine which features show a strong statistical relationship with the target variable.\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "selector = SelectKBest(f_classif, k=2) \n",
    "X_new = selector.fit_transform(X, y)\n",
    "X_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
